# ğŸ¥ Guide DÃ©mo VidÃ©o - Pipeline Sneakers Kafka â†’ Snowflake

## ğŸ“‹ **RÃ©sumÃ© du Projet**
Pipeline temps rÃ©el qui gÃ©nÃ¨re des commandes sneakers, les envoie vers Kafka/Redpanda, et les charge automatiquement dans Snowflake.

---

## ğŸ—ï¸ **Architecture CrÃ©Ã©e**

```
ğŸ“± Producer (Python) â†’ ğŸ“¨ Kafka/Redpanda â†’ ğŸ Consumer (Python) â†’ â„ï¸ Snowflake
```

### **Composants :**
- **Redpanda** : Kafka compatible (port 19092)
- **Console Web** : Interface Kafka (port 8080)
- **Producer** : GÃ©nÃ¨re commandes sneakers
- **Consumer** : Charge vers Snowflake
- **Docker** : Orchestration complÃ¨te

---

## ğŸ“ **Structure des Fichiers CrÃ©Ã©s**

```
ETL Warehouse/
â”œâ”€â”€ docker-compose.yml          # Orchestration Docker
â”œâ”€â”€ Dockerfile                  # Image Python avec dÃ©pendances
â”œâ”€â”€ data_generator.py           # GÃ©nÃ©rateur donnÃ©es sneakers
â”œâ”€â”€ load_to_snowflake.py        # Chargement batch initial
â”œâ”€â”€ env_variables.txt           # Variables d'environnement
â””â”€â”€ src/
    â”œâ”€â”€ producer_order_status.py    # Producer Kafka
    â””â”€â”€ consumer_to_snowflake.py    # Consumer Snowflake
```

---

## ğŸ³ **1. Configuration Docker**

### **docker-compose.yml** (services principaux)
```yaml
services:
  redpanda:
    image: docker.redpanda.com/redpandadata/redpanda:latest
    ports:
      - "19092:19092"  # Kafka
      - "8080:8080"    # Console Web
  
  producer:
    image: kafka-lab:latest
    command: ["python", "-u", "src/producer_order_status.py"]
  
  consumer:
    image: kafka-lab:latest
    command: ["python", "-u", "src/consumer_to_snowflake.py"]
```

### **Dockerfile**
```dockerfile
FROM python:3.11-slim
RUN pip install kafka-python snowflake-connector-python pandas faker
WORKDIR /app
COPY . /app
```

---

## ğŸ¯ **2. GÃ©nÃ©rateur de DonnÃ©es Sneakers**

### **Marques et ModÃ¨les** (dans data_generator.py)
```python
SNEAKER_BRANDS = [
    ("Nike", ["Air Max", "Air Force 1", "Dunk", "Jordan"]),
    ("Adidas", ["Stan Smith", "Superstar", "Yeezy", "Ultra Boost"]),
    ("New Balance", ["990", "574", "327", "2002R"]),
    # ... 8 marques au total
]
```

### **Exemple de Produit GÃ©nÃ©rÃ©**
```json
{
  "product_name": "Nike Air Max 90 White Leather - Size 42",
  "brand": "Nike",
  "model": "Air Max 90",
  "color": "White",
  "size": "42",
  "unit_price": 120.50
}
```

---

## ğŸ“¨ **3. Producer Kafka (src/producer_order_status.py)**

### **Code Principal**
```python
def generate_sneaker_order_event(customers_df, inventory_df):
    customer = customers_df.sample(1).iloc[0]
    product = inventory_df.sample(1).iloc[0]
    
    order_event = {
        "event_type": "order_created",
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "order_id": random.randint(10000, 99999),
        
        # Info client
        "customer_name": customer['name'],
        "customer_email": customer['email'],
        
        # Info sneaker
        "brand": product['brand'],
        "model": product['model'],
        "size": product['size'],
        "unit_price": float(product['unit_price']),
        "total_amount": float(product['unit_price']) * quantity
    }
    return order_event
```

### **Envoi vers Kafka**
```python
producer = KafkaProducer(
    bootstrap_servers=['redpanda:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

future = producer.send('sneaker-orders', value=order_event)
```

---

## ğŸ“¥ **4. Consumer Snowflake (src/consumer_to_snowflake.py)**

### **Lecture Kafka**
```python
consumer = KafkaConsumer(
    'sneaker-orders',
    bootstrap_servers=['redpanda:9092'],
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

for message in consumer:
    event_data = message.value
    # Traitement...
```

### **Chargement Snowflake**
```python
df = pd.DataFrame([event_data])
write_pandas(
    snowflake_conn, 
    df, 
    table_name='STREAMING_ORDERS',
    database='RETAIL_LAB',
    schema='STG'
)
```

---

## ğŸš€ **5. Commandes de DÃ©monstration**

### **Setup Initial**
```bash
# 1. Charger variables d'environnement
source env_variables.txt

# 2. Construire l'image Docker
docker build -t kafka-lab:latest .

# 3. DÃ©marrer Redpanda + Console
docker-compose up -d redpanda console
```

### **CrÃ©er le Topic**
```bash
docker exec redpanda rpk topic create sneaker-orders --partitions 3
```

### **Lancer le Pipeline**
```bash
# 4. DÃ©marrer le producer (gÃ©nÃ¨re commandes)
docker-compose up -d producer

# 5. DÃ©marrer le consumer (charge Snowflake)
docker-compose up -d consumer
```

### **Monitoring en Live**
```bash
# Voir les logs en temps rÃ©el
docker-compose logs -f producer consumer

# VÃ©rifier les topics Kafka
docker exec redpanda rpk topic list
```

---

## ğŸ” **6. Points de VÃ©rification pour la VidÃ©o**

### **Console Web Redpanda** : http://localhost:8080
- **Topics** â†’ sneaker-orders
- Voir les messages JSON en temps rÃ©el
- Partitions et offsets

### **Logs Producer**
```
âœ… [1] Commande envoyÃ©e: Nike Air Max 90 Size 42 â†’ 120.50â‚¬
   ğŸ“ Partition: 0, Offset: 0
```

### **Logs Consumer**
```
ğŸ“¥ Ã‰vÃ©nement reÃ§u: Order 12345
   ğŸ·ï¸ Nike Air Max 90 Size 42
   ğŸ’° 120.50â‚¬
âœ… ChargÃ© dans Snowflake! Total traitÃ©: 1
```

### **Snowflake** : https://gupyoza-zq65095.snowflakecomputing.com
```sql
USE WAREHOUSE TEACH_WH;
USE DATABASE RETAIL_LAB;
USE SCHEMA STG;

-- Voir les commandes streaming
SELECT BRAND, MODEL, SIZE, TOTAL_AMOUNT, PROCESSED_AT 
FROM STREAMING_ORDERS 
ORDER BY PROCESSED_AT DESC 
LIMIT 10;
```

---

## ğŸ“Š **7. DonnÃ©es Exemple GÃ©nÃ©rÃ©es**

### **Commandes Typiques**
- Nike Air Max 90 White Size 42 â†’ 120.50â‚¬
- Adidas Yeezy Boost 350 Black Size 41 â†’ 220.00â‚¬
- New Balance 990v5 Grey Size 43 â†’ 180.75â‚¬

### **FrÃ©quence**
- 1 commande toutes les 2-8 secondes
- Distribution rÃ©aliste des tailles (40-43 plus frÃ©quentes)
- Prix variables selon marque et Ã©dition

---

## ğŸ¬ **8. Script de PrÃ©sentation SuggÃ©rÃ©**

1. **Montrer l'architecture** (diagramme)
2. **Code du producer** (gÃ©nÃ©ration Ã©vÃ©nements)
3. **Lancer les commandes** Docker
4. **Console Redpanda** (messages temps rÃ©el)
5. **Logs des services** (producer + consumer)
6. **Snowflake** (donnÃ©es arrivÃ©es)
7. **Statistiques** (requÃªtes SQL)

---

## âš¡ **Commandes Rapides pour Live Demo**

```bash
# Reset complet
docker-compose down && docker-compose up -d redpanda console

# CrÃ©er topic
docker exec redpanda rpk topic create sneaker-orders --partitions 3

# Lancer pipeline
docker-compose up -d producer consumer

# Monitoring
docker-compose logs -f producer consumer
```



